{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<h3>Student Information</h3> Please provide information about yourself. We will NOT grade this submissing w/o all the information<br>\n",
    "<b>Name</b>: Avantika Yellapantula<br>\n",
    "<b>NetID</b>:ay257<br> \n",
    "<b>Recitation (01/02)</b>: 01<br>\n",
    "<b>Notes to Grader</b> (optional):<br>\n",
    "<br><br>\n",
    "<b>IMPORTANT</b>\n",
    "Your work will not be graded withour your initials below<br>\n",
    "I certify that this lab represents my own work and I have read the RU academic intergrity policies at<br>\n",
    "<a href=\"https://www.cs.rutgers.edu/academic-integrity/introduction\">https://www.cs.rutgers.edu/academic-integrity/introduction </a><br>\n",
    "<b>Initials</b>: AY     (eg: DS for Deeptanshu Singh)\n",
    "\n",
    "\n",
    "<h3>Grader Notes</h3>\n",
    "<b>Your Grade<b>:<br>\n",
    "<b>Grader Initials</b>:<br>\n",
    "<b>Grader Comments</b> (optional):<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "intro",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## CS 439 - Introduction to Data Science\n",
    "### Spring 2019\n",
    "\n",
    "# Lab 3: Data Cleaning and Visualization\n",
    "\n",
    "### Due Date: Sunday February 17, 2019 by 11:59 PM ###\n",
    "\n",
    "### Instructions\n",
    "This lab is presented as a notebook. Please execute the cells that are already completed and your task is to fill in the code\n",
    "between ### BEGIN SOLUTION ### and ### END SOLUTION ###. \n",
    "\n",
    "#### Important: Please do not add any new cells or change the order of cells. If you have questions, please contact the courseS staff.\n",
    "\n",
    "In this lab, you will be working with a dataset from NYPD containing data on calls to the New York Police Department. Information about the datasets can be found https://opendata.cityofnewyork.us/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "setup",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Setup\n",
    "\n",
    "Note that after activating matplotlib to display figures inline via the IPython magic `%matplotlib inline`, we configure a custom default figure size. Virtually every default aspect of matplotlib [can be customized](https://matplotlib.org/users/customizing.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "imports",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "part1",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "# Part 1:Getting Data\n",
    "\n",
    "We will work with the NYPD Historic complaint data set. Our first task is to estimate the size of this download by looking at the number of rows, columns and using an estimated size for a column (use a reasonable value). The site metadata is available from the page\n",
    "https://data.cityofnewyork.us/Public-Safety/NYPD-Complaint-Data-Historic/qgea-i56i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "#The number of rows and columns are available from the meta-data website. There are\n",
    "#6.04 million rows and 35 columns.\n",
    "\n",
    "#                                      Num_obs*Vars*Width + 4*Num_obs\n",
    "#       number of megabytes  =  M  =  --------------------------------\n",
    "#                                                   1024^2\n",
    "#\n",
    "# The number of observations is 6.04M*35=211,400,000\n",
    "# The number of variables are the number of columns, which is 35\n",
    "# I will use the width of an integer (4)\n",
    "\n",
    "# So the math gives us: 5,966,753,388,257.599\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Download the data\n",
    "This file is large (use the estimate you did above). If it takes too long to download, you may want to interrupt and download the file using a browser and URL https://data.cityofnewyork.us/Public-Safety/NYPD-Complaint-Data-Historic/qgea-i56i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "download-data",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import utils\n",
    "data_dir = 'data'\n",
    "data_url = 'https://data.cityofnewyork.us/Public-Safety/NYPD-Complaint-Data-Historic/qgea-i56i'\n",
    "\n",
    "file_name = 'NYPD_Complaint_Data_Historic.csv'\n",
    "\n",
    "# To retrieve the dataset, we will use the `utils.fetch_and_cache` utility from utils library. \n",
    "dest_path = utils.fetch_and_cache(data_url=data_url, file=file_name,data_dir=data_dir)\n",
    "print(f'Located at {dest_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Inspect the size of the file\n",
    "It is helpful to get an idea of the size of the file. This can be done using functions in the utils library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q0",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1898173978"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at the size of the file w/o opening it using OS (https://docs.python.org/3/library/os.html). You can perform\n",
    "# variety of operating system related functions from this package.\n",
    "### BEGIN SOLUTION\n",
    "import os\n",
    "statinfo = os.stat('C:/Users/avocado/Desktop/Spring 2019/DS/Labs/Lab3/Lab3/data/NYPD_Complaint_Data_Historic.csv')\n",
    "statinfo.st_size\n",
    "#### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Split the large file\n",
    "This data file NYPD_Complaint_Data_Historic.csv is too big to load into a single DataFrame. Let us split the large file into smaller files.  Let us find out the number of lines in the NYPD_Complaint_Data_Historic.csv file using utils."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using utils library, find the number of lines in the file\n",
    "from utils import line_count\n",
    "print(\"Lines in the calls file\", line_count('C:/Users/avocado/Desktop/Spring 2019/DS/Labs/Lab3/Lab3/data/NYPD_Complaint_Data_Historic.csv'))\n",
    "#%ls\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the file into 10 smaller files. Estimate the number of lines in each file using the count above\n",
    "# files should be created in the data folder and named NYPD_Complaint_Data_Historic_1.csv, \n",
    "# NYPD_Complaint_Data_Historic_2.csv, ... NYPD_Complaint_Data_Historic_10.csv etc\n",
    "# It is possible that few lines from the original file may not be saved due to rounding errors.\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "# import sys\n",
    "# orig_file = 'data/NYPD_Complaint_Data_Historic.csv'\n",
    "# csvfilename = open('data/NYPD_Complaint_Data_Historic.csv', 'r').readlines()\n",
    "# lines_per_file = 100000  # gives about 25 MB\n",
    "# file = 1\n",
    "# for i in range(len(csvfilename)):\n",
    "#    if i % lines_per_file == 0:\n",
    "#      open(str(orig_file)+ str(file) + '.csv', 'w+').writelines(csvfilename[i:i+lines_per_file])\n",
    "#    file += 1\n",
    "# # this actually creates more managable files of size 25MB each\n",
    "\n",
    "\n",
    "# above code doesn't work for shit because the file is over 1gb\n",
    "# can't just use open(filename,'r') either because that would say that the type_IO error\n",
    "# is subscriptable.\n",
    "\n",
    "import os\n",
    "\n",
    "def split(filehandler, delimiter=',', row_limit=604000,\n",
    "          output_name_template='NYPD_Complaint_Data_Historic_%s.csv', output_path='C:/Users/avocado/Desktop/Spring 2019/DS/Labs/Lab3/Lab3/data', keep_headers=True):\n",
    "    import csv\n",
    "    reader = csv.reader(filehandler, delimiter=delimiter)\n",
    "    current_piece = 1\n",
    "    current_out_path = os.path.join(\n",
    "        output_path,\n",
    "        output_name_template % current_piece\n",
    "    )\n",
    "    current_out_writer = csv.writer(open(current_out_path, 'w'), delimiter=delimiter)\n",
    "    current_limit = row_limit\n",
    "    if keep_headers:\n",
    "        headers = next(reader)\n",
    "        current_out_writer.writerow(headers)\n",
    "    for i, row in enumerate(reader):\n",
    "        if i + 1 > current_limit:\n",
    "            current_piece += 1\n",
    "            current_limit = row_limit * current_piece\n",
    "            current_out_path = os.path.join(\n",
    "                output_path,\n",
    "                output_name_template % current_piece\n",
    "            )\n",
    "            current_out_writer = csv.writer(open(current_out_path, 'w'), delimiter=delimiter)\n",
    "            if keep_headers:\n",
    "                current_out_writer.writerow(headers)\n",
    "        current_out_writer.writerow(row)\n",
    "\n",
    "split(open('data/NYPD_Complaint_Data_Historic.csv', 'r'));        \n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Check the files in the data folder\n",
    "Now, we'll use a method of the `Pathlib.Path` class called `glob` to list all files in the `data` directory. You will find useful information in pathlib [docs](https://docs.python.org/3/library/pathlib.html).\n",
    "\n",
    "Below, we use pathlib's `glob` method to store the list of all files' names from the `data_dir` directory in the variable `file_names`. These names should be strings that contain only the file name (e.g. `dummy.txt` not `data/dummy.txt`). The asterisk (*) character is used with the `glob` method to match any string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NYPD_Complaint_Data_Historic.csv',\n",
       " 'NYPD_Complaint_Data_Historic_1.csv',\n",
       " 'NYPD_Complaint_Data_Historic_10.csv',\n",
       " 'NYPD_Complaint_Data_Historic_2.csv',\n",
       " 'NYPD_Complaint_Data_Historic_3.csv',\n",
       " 'NYPD_Complaint_Data_Historic_4.csv',\n",
       " 'NYPD_Complaint_Data_Historic_5.csv',\n",
       " 'NYPD_Complaint_Data_Historic_6.csv',\n",
       " 'NYPD_Complaint_Data_Historic_7.csv',\n",
       " 'NYPD_Complaint_Data_Historic_8.csv',\n",
       " 'NYPD_Complaint_Data_Historic_9.csv']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "data_dir_path = Path('data') # creates a Path object that points to the data directory\n",
    "file_names = [x.name for x in data_dir_path.glob('*') if x.is_file()]\n",
    "file_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Pre-processing of data\n",
    "It is good to pre-process the data to see if the file can be opened in a Jupyter notebook. We need to avoid large files that can crash notebooks. Typically, files of size around 200 MB is ok to open into a DataFrame. In the following activities we will inspect the file w/o opening it as a DataFrame. Using utils.head "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CMPLNT_NUM,CMPLNT_FR_DT,CMPLNT_FR_TM,CMPLNT_TO_DT,CMPLNT_TO_TM,ADDR_PCT_CD,RPT_DT,KY_CD,OFNS_DESC,PD_CD,PD_DESC,CRM_ATPT_CPTD_CD,LAW_CAT_CD,BORO_NM,LOC_OF_OCCUR_DESC,PREM_TYP_DESC,JURIS_DESC,JURISDICTION_CODE,PARKS_NM,HADEVELOPT,HOUSING_PSA,X_COORD_CD,Y_COORD_CD,SUSP_AGE_GROUP,SUSP_RACE,SUSP_SEX,TRANSIT_DISTRICT,Latitude,Longitude,Lat_Lon,PATROL_BORO,STATION_NAME,VIC_AGE_GROUP,VIC_RACE,VIC_SEX\\n',\n",
       " '756486364,12/10/2013,17:30:00,12/10/2013,22:30:00,52,12/11/2013,107,BURGLARY,223,\"BURGLARY,RESIDENCE,NIGHT\",COMPLETED,FELONY,BRONX,INSIDE,RESIDENCE - APT. HOUSE,N.Y. POLICE DEPT,0,NA,,NA,1014994,256310,,UNKNOWN,U,,40.870140948,-73.888840951,\"(40.870140948, -73.888840951)\",PATROL BORO BRONX,,45-64,BLACK HISPANIC,M\\n',\n",
       " '306416158,12/10/2013,17:30:00,12/10/2013,17:35:00,24,12/11/2013,578,HARRASSMENT 2,638,\"HARASSMENT,SUBD 3,4,5\",COMPLETED,VIOLATION,MANHATTAN,INSIDE,DOCTOR/DENTIST OFFICE,N.Y. POLICE DEPT,0,NA,,NA,992349,225599,,WHITE,M,,40.785897843,-73.970755108,\"(40.785897843, -73.970755108)\",PATROL BORO MAN NORTH,,25-44,BLACK HISPANIC,F\\n',\n",
       " '139408975,12/10/2013,17:30:00,12/11/2013,16:00:00,75,12/11/2013,341,PETIT LARCENY,338,\"LARCENY,PETIT FROM BUILDING,UN\",COMPLETED,MISDEMEANOR,BROOKLYN,INSIDE,RESIDENCE - PUBLIC HOUSING,N.Y. HOUSING POLICE,2,NA,UNITY PLAZA (SITES 4-27),411,1012521,182427,,,,,40.667359783,-73.89809329,\"(40.667359783, -73.89809329)\",PATROL BORO BKLYN NORTH,,,UNKNOWN,D\\n',\n",
       " '750839719,12/10/2013,17:30:00,12/11/2013,18:00:00,47,12/11/2013,341,PETIT LARCENY,301,\"LARCENY,PETIT BY ACQUIRING LOS\",COMPLETED,MISDEMEANOR,BRONX,INSIDE,DEPARTMENT STORE,N.Y. POLICE DEPT,0,NA,,NA,1023421,264177,,,,,40.89170002,-73.858325648,\"(40.89170002, -73.858325648)\",PATROL BORO BRONX,,25-44,BLACK,M\\n']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the util.head() to read up to 5 lines from the original file (w/o opening it)\n",
    "from utils import head\n",
    "head('data/NYPD_Complaint_Data_Historic.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Inspecting and describing data columns\n",
    "There should be 35 columns in each record. Using header information and data types, describe the type of data in each\n",
    "column. If you are unable to determine, just state so.\n",
    "##### BEGIN SOLUTION\n",
    "* CMPLNT_NUM : \n",
    "* CMPLNT_FR_DT: \n",
    "* CMPLNT_FR_TM:\n",
    "* CMPLNT_TO_DT:\n",
    "* CMPLNT_TO:\n",
    "* ....\n",
    "* VIC_RACE:\n",
    "* VIC_SEX:\n",
    "##### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "explore-0",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "# Part 2 - Exploratory Data Analysis\n",
    "Exploratory data analysis (EDA) is the process of examining a subest of a large data set to see what we can know about the data. First we will explore one file NYPD_Complaint_Data_Historic_1.csv to see what we can find out.\n",
    "\n",
    "### 2.1 Loading Data into a DataFrame\n",
    "Load the first CSV file, NYPD_Complaint_Data_Historic_1.csv into a `pandas.DataFrame` object. Also do a time analysis to see how long it took to load the data into a DataFrame. Time should be printed in seconds. The time libraries https://docs.python.org/3/library/time.html can help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "explore-1",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1901426315307617\n"
     ]
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "import pandas as pd\n",
    "import time\n",
    "import sys\n",
    "time_start = time.time()    # returns the number of seconds to current time from 1/1/1970\n",
    "dfcsv1=pd.read_csv('data/NYPD_Complaint_Data_Historic_1.csv')\n",
    "time_end = time.time()\n",
    "\n",
    "elapsed_time = time_end - time_start\n",
    "print(elapsed_time)\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "explore-2",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### 2.2 Description of Fields\n",
    "Let's also check some basic information about these files using the `DataFrame.describe` and `DataFrame.info` methods. Describe columns that can be removed based on the information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "explore-3",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 604000 entries, 0 to 603999\n",
      "Data columns (total 35 columns):\n",
      "CMPLNT_NUM           604000 non-null int64\n",
      "CMPLNT_FR_DT         603956 non-null object\n",
      "CMPLNT_FR_TM         603998 non-null object\n",
      "CMPLNT_TO_DT         472813 non-null object\n",
      "CMPLNT_TO_TM         473035 non-null object\n",
      "ADDR_PCT_CD          603992 non-null float64\n",
      "RPT_DT               604000 non-null object\n",
      "KY_CD                604000 non-null int64\n",
      "OFNS_DESC            602097 non-null object\n",
      "PD_CD                603574 non-null float64\n",
      "PD_DESC              603574 non-null object\n",
      "CRM_ATPT_CPTD_CD     603999 non-null object\n",
      "LAW_CAT_CD           604000 non-null object\n",
      "BORO_NM              603565 non-null object\n",
      "LOC_OF_OCCUR_DESC    474763 non-null object\n",
      "PREM_TYP_DESC        601159 non-null object\n",
      "JURIS_DESC           604000 non-null object\n",
      "JURISDICTION_CODE    603574 non-null float64\n",
      "PARKS_NM             1042 non-null object\n",
      "HADEVELOPT           29918 non-null object\n",
      "HOUSING_PSA          46799 non-null float64\n",
      "X_COORD_CD           603988 non-null float64\n",
      "Y_COORD_CD           603988 non-null float64\n",
      "SUSP_AGE_GROUP       113036 non-null object\n",
      "SUSP_RACE            292479 non-null object\n",
      "SUSP_SEX             292479 non-null object\n",
      "TRANSIT_DISTRICT     12863 non-null float64\n",
      "Latitude             603988 non-null float64\n",
      "Longitude            603988 non-null float64\n",
      "Lat_Lon              603988 non-null object\n",
      "PATROL_BORO          603500 non-null object\n",
      "STATION_NAME         12863 non-null object\n",
      "VIC_AGE_GROUP        415009 non-null object\n",
      "VIC_RACE             603999 non-null object\n",
      "VIC_SEX              603999 non-null object\n",
      "dtypes: float64(9), int64(2), object(24)\n",
      "memory usage: 106.0+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CMPLNT_NUM</th>\n",
       "      <th>ADDR_PCT_CD</th>\n",
       "      <th>KY_CD</th>\n",
       "      <th>PD_CD</th>\n",
       "      <th>JURISDICTION_CODE</th>\n",
       "      <th>HOUSING_PSA</th>\n",
       "      <th>X_COORD_CD</th>\n",
       "      <th>Y_COORD_CD</th>\n",
       "      <th>TRANSIT_DISTRICT</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.040000e+05</td>\n",
       "      <td>603992.000000</td>\n",
       "      <td>604000.000000</td>\n",
       "      <td>603574.000000</td>\n",
       "      <td>603574.000000</td>\n",
       "      <td>46799.000000</td>\n",
       "      <td>6.039880e+05</td>\n",
       "      <td>603988.000000</td>\n",
       "      <td>12863.000000</td>\n",
       "      <td>603988.000000</td>\n",
       "      <td>603988.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.506378e+08</td>\n",
       "      <td>63.851955</td>\n",
       "      <td>293.267604</td>\n",
       "      <td>413.477383</td>\n",
       "      <td>0.802303</td>\n",
       "      <td>7076.263360</td>\n",
       "      <td>1.005028e+06</td>\n",
       "      <td>206676.923399</td>\n",
       "      <td>14.129752</td>\n",
       "      <td>40.733914</td>\n",
       "      <td>-73.924998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.597364e+08</td>\n",
       "      <td>34.456046</td>\n",
       "      <td>148.487350</td>\n",
       "      <td>219.521342</td>\n",
       "      <td>6.992332</td>\n",
       "      <td>14596.281384</td>\n",
       "      <td>2.146661e+04</td>\n",
       "      <td>30143.359485</td>\n",
       "      <td>12.403784</td>\n",
       "      <td>0.082740</td>\n",
       "      <td>0.077416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000024e+08</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>218.000000</td>\n",
       "      <td>9.134630e+05</td>\n",
       "      <td>121131.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>40.498905</td>\n",
       "      <td>-74.254560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.257399e+08</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>477.000000</td>\n",
       "      <td>9.918910e+05</td>\n",
       "      <td>184360.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>40.672659</td>\n",
       "      <td>-73.972428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.507877e+08</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>341.000000</td>\n",
       "      <td>386.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>696.000000</td>\n",
       "      <td>1.004535e+06</td>\n",
       "      <td>205190.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>40.729858</td>\n",
       "      <td>-73.926828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.753875e+08</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>637.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1251.000000</td>\n",
       "      <td>1.016751e+06</td>\n",
       "      <td>234532.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>40.810396</td>\n",
       "      <td>-73.882687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.999986e+08</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>881.000000</td>\n",
       "      <td>969.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>68980.000000</td>\n",
       "      <td>1.067298e+06</td>\n",
       "      <td>271820.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>40.912723</td>\n",
       "      <td>-73.700316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         CMPLNT_NUM    ADDR_PCT_CD          KY_CD          PD_CD  \\\n",
       "count  6.040000e+05  603992.000000  604000.000000  603574.000000   \n",
       "mean   5.506378e+08      63.851955     293.267604     413.477383   \n",
       "std    2.597364e+08      34.456046     148.487350     219.521342   \n",
       "min    1.000024e+08       1.000000     101.000000     101.000000   \n",
       "25%    3.257399e+08      40.000000     116.000000     254.000000   \n",
       "50%    5.507877e+08      66.000000     341.000000     386.000000   \n",
       "75%    7.753875e+08      94.000000     351.000000     637.000000   \n",
       "max    9.999986e+08     123.000000     881.000000     969.000000   \n",
       "\n",
       "       JURISDICTION_CODE   HOUSING_PSA    X_COORD_CD     Y_COORD_CD  \\\n",
       "count      603574.000000  46799.000000  6.039880e+05  603988.000000   \n",
       "mean            0.802303   7076.263360  1.005028e+06  206676.923399   \n",
       "std             6.992332  14596.281384  2.146661e+04   30143.359485   \n",
       "min             0.000000    218.000000  9.134630e+05  121131.000000   \n",
       "25%             0.000000    477.000000  9.918910e+05  184360.000000   \n",
       "50%             0.000000    696.000000  1.004535e+06  205190.000000   \n",
       "75%             0.000000   1251.000000  1.016751e+06  234532.000000   \n",
       "max            97.000000  68980.000000  1.067298e+06  271820.000000   \n",
       "\n",
       "       TRANSIT_DISTRICT       Latitude      Longitude  \n",
       "count      12863.000000  603988.000000  603988.000000  \n",
       "mean          14.129752      40.733914     -73.924998  \n",
       "std           12.403784       0.082740       0.077416  \n",
       "min            1.000000      40.498905     -74.254560  \n",
       "25%            3.000000      40.672659     -73.972428  \n",
       "50%           11.000000      40.729858     -73.926828  \n",
       "75%           30.000000      40.810396     -73.882687  \n",
       "max           34.000000      40.912723     -73.700316  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "dfcsv1.info()\n",
    "dfcsv1.describe()\n",
    "\n",
    "# What columns can be removed from the DataFrame? \n",
    "# A reasonable rule of thumb is that if a column is missing more than \n",
    "# 50% of the data then it should be removed\n",
    "\n",
    "# Going by this rule of thumb, the following data columns should be removed\n",
    "# PARKS_NM             1042 non-null object\n",
    "# HADEVELOPT           29918 non-null object\n",
    "# HOUSING_PSA          46799 non-null float64\n",
    "# TRANSIT_DISTRICT     12863 non-null float64\n",
    "# SUSP_AGE_GROUP       113036 non-null object\n",
    "# STATION_NAME         12863 non-null object\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "explore-4",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### 2.2 Finding Uniques\n",
    "\n",
    "Notice that the functions above reveal type information for the columns, as well as some basic statistics about the numerical columns found in the DataFrame. However, we still need more information about what each column represents. Let's explore the data further.\n",
    "\n",
    "find the number of unique values in each DataFrame column and answer the questions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "explore-5",
     "locked": true,
     "schema_version": 2,
     "solution": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CMPLNT_NUM           604000\n",
       "CMPLNT_FR_DT           2035\n",
       "CMPLNT_FR_TM           1440\n",
       "CMPLNT_TO_DT           1391\n",
       "CMPLNT_TO_TM           1440\n",
       "ADDR_PCT_CD              77\n",
       "RPT_DT                  449\n",
       "KY_CD                    69\n",
       "OFNS_DESC                59\n",
       "PD_CD                   366\n",
       "PD_DESC                 356\n",
       "CRM_ATPT_CPTD_CD          2\n",
       "LAW_CAT_CD                3\n",
       "BORO_NM                   5\n",
       "LOC_OF_OCCUR_DESC         5\n",
       "PREM_TYP_DESC            70\n",
       "JURIS_DESC               20\n",
       "JURISDICTION_CODE        20\n",
       "PARKS_NM                348\n",
       "HADEVELOPT              266\n",
       "HOUSING_PSA             386\n",
       "X_COORD_CD            52580\n",
       "Y_COORD_CD            55685\n",
       "SUSP_AGE_GROUP            6\n",
       "SUSP_RACE                 7\n",
       "SUSP_SEX                  3\n",
       "TRANSIT_DISTRICT         12\n",
       "Latitude              77379\n",
       "Longitude             77382\n",
       "Lat_Lon               77389\n",
       "PATROL_BORO               8\n",
       "STATION_NAME            364\n",
       "VIC_AGE_GROUP             6\n",
       "VIC_RACE                  7\n",
       "VIC_SEX                   4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "dfcsv1.nunique()\n",
    "\n",
    "# Questions\n",
    "# 1. How many distinct locations where the complaints have come from? 5\n",
    "# 2. How many age groups are represented in the data set?  6\n",
    "# 3. How many boroughs are included in the data set? 5\n",
    "# 4. How many offense types are listed in this data set? 59\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Offense by Boro\n",
    "Using GroupBy operation, create a DataFrame that groups offenses by Boro. call the DataFrame calls_by_Boro_and_offense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q1a-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "calls_by_Boro_and_offense=dfcsv1.groupby(['OFNS_DESC','BORO_NM'])\n",
    "# for name,group in calls_by_Boro_and_offense:\n",
    "#    print(name)\n",
    "#    print(group)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q1a-tests",
     "locked": true,
     "points": 1,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Columns not found: 'GRAND LARCENY', 'BRONX'\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-8e35cf692637>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## Assert that in Bronx there were 6022 Grand Larceny incidents\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m### BEGIN SOLUTION\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0mcalls_by_Boro_and_offense\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'BRONX'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'GRAND LARCENY'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m6022\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m### END SOLUTION\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\pandas\\core\\base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    263\u001b[0m                 \u001b[0mbad_keys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdifference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m                 raise KeyError(\"Columns not found: {missing}\"\n\u001b[1;32m--> 265\u001b[1;33m                                .format(missing=str(bad_keys)[1:-1]))\n\u001b[0m\u001b[0;32m    266\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gotitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Columns not found: 'GRAND LARCENY', 'BRONX'\""
     ]
    }
   ],
   "source": [
    "## Assert that in Bronx there were 6022 Grand Larceny incidents\n",
    "### BEGIN SOLUTION\n",
    "assert calls_by_Boro_and_offense['BRONX', 'GRAND LARCENY'] == 6022\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q1b",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### 2.4 Offenses in Bronx\n",
    "\n",
    "In the cell below, find a list of strings corresponding to the possible values for `OFNS_DESC` when `BORO` is \"BRONX\". Create an expression that automatically extracts the names of the offenses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q1b-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-e045ba1d2e3a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m### BEGIN SOLUTION\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdf_boro\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdfcsv1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'BORO_NM'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'OFNS_DESC'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mboro\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moffense\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf_boro\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboro\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moffense\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "df_boro=dfcsv1[['BORO_NM','OFNS_DESC']].copy()\n",
    "for boro,offense in df_boro:\n",
    "    print(boro)\n",
    "    print(offense)\n",
    "### END SOLUTION\n",
    "\n",
    "# How many offenses were committed in Bronx during the analysis period?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### 2.5 Most Common Crimes in NYC\n",
    "\n",
    "What are the five crime types of OFNS_DESC that have the most crime events in Bronx? You may need to use `value_counts` to find the answer. Save your results as a list of strings.\n",
    "\n",
    "**Hint:** *The `keys` method of the Series class might be useful.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Probability of a Crime in Bronx\n",
    "What is the probability that a the crime \"Arson\" can happen in Bronx?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q2-tests",
     "locked": true,
     "points": 1,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "part2",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "# Part 3: Visualizing the Data\n",
    "\n",
    "## Pandas vs. Seaborn Plotting\n",
    "\n",
    "Pandas offers basic functionality for plotting. For example, the `DataFrame` and `Series` classes both have a `plot` method. However, the basic plots generated by pandas are not particularly pretty. While it's possible to manually use matplotlib commands to make pandas plots look better, we'll instead use a high level plotting library called Seaborn that will take care of most of this for us.\n",
    "\n",
    "As you learn to do data visualization, you may find the [pandas documentation](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.plot.html) and [Seaborn documentation](https://seaborn.pydata.org/api.html) helpful!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "plot-demo",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### 3.1 Plotting a Series\n",
    "Using the built-in plotting functionality of pandas, such as `plot` method of the `Series` class to generate a `barh` plot type,  display the value counts for `OFNS_DESC` visually as a barh chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "plot-demo1",
     "locked": true,
     "schema_version": 2,
     "solution": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Getting a Better Plot\n",
    "The plot above can be messy as it plots all offenses. Plot only the offenses that has more than 10000 calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "plot-demo2",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "By contrast, the Seaborn library provides a specific function `countplot` built for plotting counts. It operates directly on the DataFrame itself i.e. there's no need to call `value_counts()` at all. This higher level approach makes it easier to work with. Use the y-label (\"Crime Category\"), x-label(\"Number of Calls\") and title_of_plot(\"Number of Calls By Crime Type\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "plot-demo3",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "plot-demo4",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "You may note that the ordering might be different for the seaborn plot (as compared to pandas plot). If we want the same ordering that we had in the pandas plot, we can use the order parameter of the `countplot` method. It takes a list of strings corresponding to the axis to be ordered. By passing the index of the `value_counts`, you can get the order you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "plot-demo5",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "plot-demo6",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Now we have a pretty bar plot with the bars ordered by size. Though `seaborn` appears to provide a superior plot from a aesthetic point of view, the `pandas` plotting library is also good to understand. You'll get practice using both libraries in the following questions.\n",
    "\n",
    "## An Additional Note on Plotting in Jupyter Notebooks\n",
    "\n",
    "You may have noticed that many of our code cells involving plotting end with a semicolon (;). This prevents any extra output from the last line of the cell that we may not want to see. Try adding this to your own code in the following questions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### 3.3 making more plots\n",
    "\n",
    "Now it is your turn to make some more plots using `pandas` and `seaborn`. Let's start by looking at the distribution of calls over days of the week.\n",
    "\n",
    "The CMPLNT_FR_DT field contains the date of the event. We would like to add a new column to the DataFrame that includes Day of the week (DAY_OF_WEEK) that indicates the day of the week. This can help us analyze the crimes on a specific day of the week. For example, we can answer questions such as \"what day of the week that a LARSON is likely to happen in NYC?\"\n",
    "\n",
    "\n",
    "Add a new column `DAY_OF_WEEK` into the `calls` dataframe that has the day string (eg. 'Sunday') for the corresponding value in CMPLNT_FR_DT. For example, if the first 3 values of `CMPLNT_FR_DT` are `['01/27/2006, '01/28/2006, '01/29/2006]`, then the first 3 values of the `DAY_OF_WEEK` column should be `[\"Friday\", \"Saturday\", \"Sunday\"]`.\n",
    "\n",
    "**Hint:** *Try using the [Series.map](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.map.html) function on `calls[\"OFNS_DESC\"]`.  Can you assign this to the new column `calls[\"DAY_OF_WEEK\"]`?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3a-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "days = [\"Sunday\", \"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\"]\n",
    "### BEGIN SOLUTION\n",
    "\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3b",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### 3.4 Seaborn plots\n",
    "\n",
    "Create a `seaborn` plot that shows the number of calls for each day of the week. You may want to use of the `rotation` argument in `ax.set_xticklabels`, which rotates the labels by 90 degrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3b-ex",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3b-instructions",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Now, let's make the same plot using `pandas`. Construct a vertical bar plot with the count of the number of calls (entries in the table) for each day of the week **ordered by the day of the week** (eg. `Sunday`, `Monday`, ...). Do not use `sns` for this plot. Be sure that your axes are labeled and that your plot is titled.\n",
    "\n",
    "**Hint:** *Given a series `s`, and an array `coolIndex` that has the same entries as in `s.index`, `s[coolIndex]` will return a copy of the series in the same order as `coolIndex`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3b-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q4",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## 3.5 What Day of the Week is more calls?\n",
    "\n",
    "Is it true that weekdays generally have slightly more calls than Saturday or Sunday? What can you say about the difference?\n",
    "\n",
    "##### BEGIN SOLUTION\n",
    "\n",
    "\n",
    "##### END SOLUTION\n",
    "\n",
    "We can break down into some particular types of events to see their distribution. For example, let's make a bar plot for the OFNS_DESC \"HARRASSMENT 2\". Which day is the peak for \"HARRASSMENT 2\"?\n",
    "\n",
    "This time, use `seaborn` to create a vertical bar plot of the number of total noise violations reported on each day of the week, again ordered by the days of the week starting with Sunday. Do not use `pandas` to plot.\n",
    "\n",
    "**Hint:** *If you're stuck, use the code for the seaborn plot in above question as a starting point.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q4a-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q4b",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### 3.6 \n",
    "\n",
    "Do you see anything interesting about the distribution of HARRASSMENT 2 calls over a week? Type a short answer below.\n",
    "##### BEGIN SOLUTION\n",
    "\n",
    "##### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q5",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### 3.7 More Plots\n",
    "\n",
    "Let's look at a similar distribution but for a crime we have much more calls data about. In the cell below, create the same plot as you did in previous questions, but now looking at instances of the OFNS_DESC \"BURGLARY\" (instead of \"HARRASSMENT 2\"). Use either `pandas` or `seaborn` plotting as you desire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q5-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "\n",
    "### END SOLUTION\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q6",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### 3.8 time of events\n",
    "\n",
    "Now let's look at the CMPLNT_TO_TM column which indicates the time for events. Since it contains hour and minute information, let's extract the hour info and create a new column named `Hour` in the `calls` dataframe. You should save the hour as an `int`. Then plot the frequency of each hour in the table (i.e., `value_counts()`) sorted by the hour of the day (i.e., `sort_index()`).\n",
    "\n",
    "You will want to look into how to use:\n",
    "\n",
    "* [Series.str.slice](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.str.slice.html#pandas.Series.str.slice) to select the substring.\n",
    "* [Series.astype](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.astype.html) to change the type.\n",
    "\n",
    "**Hint:** *The `str` helper member of a series can be used to grab substrings.  For example, `calls[\"CMPLNT_TO_TM\"].str.slice(3,5)` returns the minute of each hour of the `CMPLNT_TO_TM`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q6a-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "pandas-fraud-plot",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Create a pandas bar plot showing the number of BURGLARY crimes committed at each hour of the day. Use the labels\n",
    "* ax.set_xlabel(\"Hour of the Day\")\n",
    "* ax.set_ylabel(\"Number of Calls\")\n",
    "* ax.set_title(\"Number of Calls Reporting Fraud For Each Day of the Week\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "pandas-fraud-plot-code",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q6b",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### 3.9 More plots\n",
    "\n",
    "In the cell below, create a seaborn plot of the same data. Again, make sure you provide axes labels and a title for your plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q6b-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q6c",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### 3.8 Spike in burglary?\n",
    "\n",
    "According to your plots, is there a spike in calls reporting BURGLARY at any particular time? If so, Do you trust that this spike is legitimate, or could there be an issue with our data? Explain your reasoning in 1-2 sentences below.\n",
    "\n",
    "#### BEGIN SOLUTION\n",
    "\n",
    "\n",
    "#### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q7",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "In the cell below, we generate a boxplot which examines the hour of day of each crime broken down by the `OFNS_DESC` value.  To construct this plot we used the [DataFrame.boxplot](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.boxplot.html) documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q7-pandas-boxplot",
     "locked": true,
     "schema_version": 2,
     "solution": false
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "calls.boxplot(column=\"Hour\", by='OFNS_DESC', rot=90);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q7-instructions",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "While the pandas boxplot is informative, we can use seaborn to create a more visually-appealing plot. Using seaborn, regenerate a better box plot. See either the textbook (https://www.textbook.ds100.org/ch/06/viz_quantitative.html) or the [seaborn boxplot documentation](https://seaborn.pydata.org/generated/seaborn.boxplot.html).\n",
    "\n",
    "Looking at your plot, which crime type appears to have the largest interquartile range? Put your results into `answer` as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q7-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Todo: Make a boxplot with seaborn\n",
    "### BEGIN SOLUTION\n",
    "ax = * Your code here *\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=90)\n",
    "ax.set_title(\"Distributions of Calls Over Hours in a Day, Grouped by Crime\");\n",
    "answer = \"Your Answer here\"\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9 - Visualization of crimes on a Map of NYC\n",
    "finally we attempt to visualize the crimes committed in NYC on a Map. First we need to installing some mapping software. run the cell below to install folium package for mapping software."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot the maps for BURGLARY in NYC\n",
    "### if it takes too much time or map does not show up, try plotting a subset of the data set of for a specific crime\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations !!!\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<h2>Submission Instructions</h2> \n",
    "<b> File Name:</b> Please name the file as your_section_your_netID_Lab3.jpynb<br>\n",
    "<b> Submit To: </b> Canvas &rarr; Assignments &rarr; Lab3 <br>\n",
    "<b>Warning:</b> Failure to follow directions may result in loss of points.<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "finish",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Credits: Josh Hug, and Berkeley Data Science Group for their contributions to the original version."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
